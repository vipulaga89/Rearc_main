{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ruMd6uL58m1"
      },
      "source": [
        "**Rearc assignment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZuyImLWwrMF"
      },
      "source": [
        "Part 1 - Pulling the data from the URL and viewign it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Part 0 - pip installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ace_tools in c:\\users\\agarw\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install ace_tools\n",
        "pip install pandas\n",
        "pip install boto3\n",
        "pip install google"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Part 1 - Using the data to print sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sb8O2QjlrAJp",
        "outputId": "4a6f1ad6-1bb7-4ff5-c248-cd0d61f41f09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ID Nation         Nation  ID Year  Year  Population    Slug Nation\n",
            "0    01000US  United States     2023  2023   332387540  united-states\n",
            "1    01000US  United States     2022  2022   331097593  united-states\n",
            "2    01000US  United States     2021  2021   329725481  united-states\n",
            "3    01000US  United States     2020  2020   326569308  united-states\n",
            "4    01000US  United States     2019  2019   324697795  united-states\n",
            "5    01000US  United States     2018  2018   322903030  united-states\n",
            "6    01000US  United States     2017  2017   321004407  united-states\n",
            "7    01000US  United States     2016  2016   318558162  united-states\n",
            "8    01000US  United States     2015  2015   316515021  united-states\n",
            "9    01000US  United States     2014  2014   314107084  united-states\n",
            "10   01000US  United States     2013  2013   311536594  united-states\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://datausa.io/api/data?drilldowns=Nation&measures=Population\"\n",
        "response = requests.get(url)\n",
        "data = response.json()\n",
        "\n",
        "records = data[\"data\"]\n",
        "df = pd.DataFrame(records)\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMvyt-xMwpuz"
      },
      "source": [
        "Part 2 - Using the data to push it over the S3 bucket in a JSON file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIf-0ZMBv7zg",
        "outputId": "ecd6e72d-a468-4c47-e90a-94bebec541b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JSON file uploaded to s3://rearc-assignment-vipul/datausa/population_1.json\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import boto3\n",
        "\n",
        "import json\n",
        "from getpass import getpass\n",
        "\n",
        "if response.status_code != 200:\n",
        "    raise Exception(f\"Failed to fetch data from API: {response.status_code}\")\n",
        "\n",
        "json_string = json.dumps(data, indent=2)\n",
        "\n",
        "aws_access_key = \"AKIAWN26JYOLIJMT26MY\"\n",
        "aws_secret_key = \"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\"\n",
        "\n",
        "# Uploading to the S3 bucket\n",
        "s3 = boto3.client(\n",
        "    's3',\n",
        "    region_name='us-east-1',\n",
        "    aws_access_key_id=aws_access_key,\n",
        "    aws_secret_access_key=aws_secret_key\n",
        ")\n",
        "\n",
        "bucket_name = 'rearc-assignment-vipul'\n",
        "object_key = 'datausa/population_1.json'\n",
        "\n",
        "s3.put_object(\n",
        "    Bucket=bucket_name,\n",
        "    Key=object_key,\n",
        "    Body=json_string,\n",
        "    ContentType=\"application/json\"\n",
        ")\n",
        "\n",
        "print(f\"JSON file uploaded to s3://{bucket_name}/{object_key}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-CbqdM1F7Z1"
      },
      "source": [
        "Part 3 - Copying the pr.data.0.Current data: Tried using the data file from the server, but google result showed, the needs to be pulled from the server for working with google colab. So changed the interpreter to Visual studio to see the API call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "-mL0RE3gDHzb",
        "outputId": "b20f90dd-2580-496d-ee0a-8c20e5f23da3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available series:\n",
            "   series_id          sector_code  class_code  measure_code  duration_code  \\\n",
            "0  PRS30006011               3000           6             1              1   \n",
            "1  PRS30006012               3000           6             1              2   \n",
            "2  PRS30006013               3000           6             1              3   \n",
            "3  PRS30006021               3000           6             2              1   \n",
            "4  PRS30006022               3000           6             2              2   \n",
            "\n",
            "  seasonal base_year  footnote_codes  begin_year begin_period  end_year  \\\n",
            "0        S         -             NaN        1988          Q01      2024   \n",
            "1        S         -             NaN        1987          Q02      2024   \n",
            "2        S      2017             NaN        1987          Q01      2024   \n",
            "3        S         -             NaN        1988          Q01      2024   \n",
            "4        S         -             NaN        1987          Q02      2024   \n",
            "\n",
            "  end_period  \n",
            "0        Q05  \n",
            "1        Q05  \n",
            "2        Q05  \n",
            "3        Q05  \n",
            "4        Q05  \n",
            "\n",
            "Data preview:\n",
            "   series_id          year period         value footnote_codes\n",
            "0  PRS30006011        1995    Q01           2.6            NaN\n",
            "1  PRS30006011        1995    Q02           2.1            NaN\n",
            "2  PRS30006011        1995    Q03           0.9            NaN\n",
            "3  PRS30006011        1995    Q04           0.1            NaN\n",
            "4  PRS30006011        1995    Q05           1.4            NaN\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "import time\n",
        "\n",
        "# Adding a slight delay to avoid rate limiting\n",
        "time.sleep(1)\n",
        "\n",
        "# Use a common browser user agent\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
        "}\n",
        "\n",
        "# First, let's get the series information to understand what's available\n",
        "series_info_url = \"https://download.bls.gov/pub/time.series/pr/pr.series\"\n",
        "series_response = requests.get(series_info_url, headers=headers)\n",
        "\n",
        "if series_response.status_code == 200:\n",
        "    # Parse the series info\n",
        "    series_data = StringIO(series_response.text)\n",
        "    series_df = pd.read_csv(series_data, sep='\\t')\n",
        "    print(\"Available series:\")\n",
        "    print(series_df.head())\n",
        "    \n",
        "    # Now try to get the actual data\n",
        "    time.sleep(2)  # Add delay between requests\n",
        "    current_data_url = \"https://download.bls.gov/pub/time.series/pr/pr.data.0.Current\"\n",
        "    current_data_response = requests.get(current_data_url, headers=headers)\n",
        "    \n",
        "    if current_data_response.status_code == 200:\n",
        "        csv_data = StringIO(current_data_response.text)\n",
        "        csv_df = pd.read_csv(csv_data, sep='\\t')\n",
        "        print(\"\\nData preview:\")\n",
        "        print(csv_df.head())\n",
        "    else:\n",
        "        print(f\"Failed to fetch data: {current_data_response.status_code}\")\n",
        "else:\n",
        "    print(f\"Failed to fetch series info: {series_response.status_code}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHb_3kkSq_Bg"
      },
      "source": [
        "Part 3 - Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from io import StringIO\n",
        "\n",
        "# Loading the uploaded BLS file (assumes you've manually uploaded it to Colab or local directory)\n",
        "bls_df = pd.read_csv(\"pr.data.0.Current.txt\", sep='\\t')\n",
        "\n",
        "# Clean column names and data\n",
        "bls_df.columns = bls_df.columns.str.strip()\n",
        "bls_df['series_id'] = bls_df['series_id'].str.strip()\n",
        "bls_df['period'] = bls_df['period'].str.strip()\n",
        "bls_df['year'] = bls_df['year'].astype(str).str.strip()\n",
        "bls_df['value'] = pd.to_numeric(bls_df['value'], errors='coerce')\n",
        "bls_df['year'] = bls_df['year'].astype(int)\n",
        "\n",
        "# Filter for quarterly data (ignore annual data or missing periods)\n",
        "bls_quarterly = bls_df[bls_df['period'].str.startswith('Q')]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# Task 1: Best Year for Each Series ID\n",
        "# -----------------------------\n",
        "# Group by series_id and year, summing value per year\n",
        "yearly_sum = bls_quarterly.groupby(['series_id', 'year'])['value'].sum().reset_index()\n",
        "\n",
        "# Find the year with max total value per series_id\n",
        "best_years = yearly_sum.loc[yearly_sum.groupby('series_id')['value'].idxmax()].sort_values('series_id')\n",
        "\n",
        "# -----------------------------\n",
        "# PART 2: Load Population Data from DataUSA API\n",
        "# -----------------------------\n",
        "\n",
        "# Fetch population JSON\n",
        "pop_url = \"https://datausa.io/api/data?drilldowns=Nation&measures=Population\"\n",
        "pop_response = requests.get(pop_url)\n",
        "pop_data = pop_response.json()['data']\n",
        "\n",
        "# Load as DataFrame\n",
        "pop_df = pd.DataFrame(pop_data)\n",
        "pop_df['Year'] = pop_df['Year'].astype(int)\n",
        "pop_df['Population'] = pd.to_numeric(pop_df['Population'], errors='coerce')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“Š Mean Population (2013â€“2018): 317437383\n",
            "ðŸ“‰ Standard Deviation: 4257090\n",
            "     series_id  year period  value  Population\n",
            "0  PRS30006032  1995    Q01    0.0         NaN\n",
            "1  PRS30006032  1996    Q01   -4.2         NaN\n",
            "2  PRS30006032  1997    Q01    2.8         NaN\n",
            "3  PRS30006032  1998    Q01    0.9         NaN\n",
            "4  PRS30006032  1999    Q01   -4.1         NaN\n",
            "5  PRS30006032  2000    Q01    0.5         NaN\n",
            "6  PRS30006032  2001    Q01   -6.3         NaN\n",
            "7  PRS30006032  2002    Q01   -6.6         NaN\n",
            "8  PRS30006032  2003    Q01   -5.7         NaN\n",
            "9  PRS30006032  2004    Q01    2.0         NaN\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------\n",
        "# Task 2: Population Stats for 2013â€“2018\n",
        "# -----------------------------\n",
        "pop_filtered = pop_df[(pop_df['Year'] >= 2013) & (pop_df['Year'] <= 2018)]\n",
        "mean_pop = pop_filtered['Population'].mean()\n",
        "std_pop = pop_filtered['Population'].std()\n",
        "\n",
        "print(\"Mean Population (2013â€“2018):\", round(mean_pop))\n",
        "print(\"Standard Deviation:\", round(std_pop))\n",
        "\n",
        "# -----------------------------\n",
        "# Task 3: Report for PRS30006032 & Q01 with Population\n",
        "# -----------------------------\n",
        "# Filter for target series_id and period\n",
        "filtered_series = bls_df[(bls_df['series_id'] == 'PRS30006032') & (bls_df['period'] == 'Q01')]\n",
        "\n",
        "# Merge with population data\n",
        "final_report = pd.merge(\n",
        "    filtered_series,\n",
        "    pop_df[['Year', 'Population']],\n",
        "    left_on='year',\n",
        "    right_on='Year',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Select relevant columns\n",
        "final_report = final_report[['series_id', 'year', 'period', 'value', 'Population']].sort_values('year')\n",
        "\n",
        "\n",
        "print(final_report.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq2oHU9PDNGQ"
      },
      "source": [
        "Calculating mean and standard deviation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hz53hg4Xwn8E"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
